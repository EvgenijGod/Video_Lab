{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интеллектуальные методы обработки видео"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. Scene Change Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательно к прочтению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Внимание!**\n",
    "\n",
    "Opencv содержит очень много высокоуровневых функций обработки изображений (например, некоторые алгоритмы компенсации движения, отслеживания объектов, распознавания образов). Использование данной библиотеки в данном задании ограничивается:\n",
    "* считыванием входного видео\n",
    "* преобразованием его кадров в другие цветовые пространства\n",
    "* использованием свёрток Собеля\n",
    "\n",
    "Использовать библиотеку numpy можно без ограничений.\n",
    "\n",
    "Если вы хотите использовать функции обработки изображений и видео из другой библиотеки, то оговорите использование этой функции в чате курса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание входных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка для тренировки лежит https://titan.gml-team.ru:5003/sharing/yX8enupJV\n",
    "\n",
    "Данные о каждом видео лежат в файле *train_dataset\\info.json*. Это список из словарей, каждый словарь содержит информацию о расположении видео, о расположении ответов на смены сцен и содержит длину видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 # Для установки opencv воспользуйтесь командой в терминале conda install -c conda-forge opencv\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "def load_json_from_file(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        return json.load(f, strict=False)\n",
    "\n",
    "\n",
    "def dump_json_to_file(obj, filename, **kwargs):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(obj, f, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'source': 'video/01.mp4', 'scene_change': 'gt/01.json', 'len': 17531},\n",
       " {'source': 'video/03.mp4', 'scene_change': 'gt/03.json', 'len': 3250},\n",
       " {'source': 'video/04.mp4', 'scene_change': 'gt/04.json', 'len': 3392},\n",
       " {'source': 'video/05.mp4', 'scene_change': 'gt/05.json', 'len': 5662},\n",
       " {'source': 'video/07.mp4', 'scene_change': 'gt/07.json', 'len': 3321},\n",
       " {'source': 'video/08.mp4', 'scene_change': 'gt/08.json', 'len': 3396},\n",
       " {'source': 'video/10.mp4', 'scene_change': 'gt/10.json', 'len': 6096},\n",
       " {'source': 'video/14.mp4', 'scene_change': 'gt/14.json', 'len': 2326},\n",
       " {'source': 'video/17.mp4', 'scene_change': 'gt/17.json', 'len': 2904},\n",
       " {'source': 'video/21.mp4', 'scene_change': 'gt/21.json', 'len': 4898},\n",
       " {'source': 'video/22.mp4', 'scene_change': 'gt/22.json', 'len': 7749}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_dataset = load_json_from_file('train_dataset/info.json')\n",
    "video_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка видео ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка видео осуществляется при помощи cv2.VideoCapture. Этот код изменять и дописывать не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==False:\n",
    "            break\n",
    "        yield frame\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое frames? Это итератор на кадры видео. Чтобы пройтись по всем кадрам последовательности, воспользуйтесь следующей конструкцией:\n",
    "*Аккуратно, по одной переменной frames можно пройти только один раз!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgenij/miniconda3/envs/evg/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f811b96a90fa42fd86c60ce5955fdf9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgenij/miniconda3/envs/evg/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1c80a106dd4cff9a4e3d14c71fe68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for frame in tqdm(frames):\n",
    "    pass\n",
    "for frame in tqdm(frames): # Второй раз уже не будет итерации\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пишем свой простой детектор смен сцен ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе предлагается написать простой Scene Change Detector (SCD) на основе выделения характеристик кадров, подсчёта разницы между кадрами на основе данных характеристик, а также подобрать наиболее оптимальный порог для этих признаков и совместить эти признаки.\n",
    "Сменой сцен в данной задаче являются только обычные мгновенные смены сцен, без дополнительных эффектов.\n",
    "\n",
    "В качестве примера приведён простой детектор смен, который считает межкадровую разницу между кадрами.\n",
    "\n",
    "*Важное замечание. Здесь и далее результатом алгоритма детектора сцен являются **индексы кадров начал сцен**, при этом кадры **нумеруются с 0**. Нулевой кадр в качестве ответа указывать не нужно*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Hard_cut.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def baseline_scene_change_detector(frames, threshold=2000, with_vis=False):\n",
    "    \"\"\"\n",
    "    Baseline SCD\n",
    "\n",
    "    Arguments:\n",
    "    frames -- iterator on video frames\n",
    "    threshold -- parameter of your algorithm (optional)\n",
    "    with_vis -- saving neighboring frames at a scene change (optional)\n",
    "\n",
    "    Returns:\n",
    "    scene_changes -- list of scene changes (idx of frames)\n",
    "    vis -- list of neighboring frames at a scene change (for visualization)\n",
    "    metric_values -- list of metric values (for visualization)\n",
    "    \"\"\"\n",
    "    \n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        # Базовое расстояние между кадрами - среднеквадратическая ошибка между ними\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "\n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    prev_frame = None\n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        # frame - это кадр\n",
    "        # idx - это номер кадра\n",
    "        if prev_frame is not None:\n",
    "            # Находим расстояние между соседними кадрами\n",
    "            metric_value = pixel_metric(frame, prev_frame)\n",
    "            if metric_value > threshold:\n",
    "                scene_changes.append(idx)\n",
    "                if with_vis:\n",
    "                    # Кадры в памяти занимают много места, поэтому сохраним лишь первые 100 срабатываний\n",
    "                    if len(vis) < 100:\n",
    "                        vis.append([prev_frame, frame])\n",
    "            metric_values.append(metric_value)\n",
    "        else:\n",
    "            metric_values.append(0)\n",
    "        prev_frame = frame\n",
    "    return scene_changes, vis, metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "cuts_base = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['cut']\n",
    "scene_changes_base, vis_base, metric_values_base = baseline_scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим визуально, насколько сильно алгоритм ошибается, а также на значения метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_error(frame, prev_frame, value):\n",
    "    fig = plt.figure(figsize=(16,4))\n",
    "    plt.suptitle('Значение метрики на текущем кадре: {:.4f}'.format(value), fontsize=24)\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax.imshow(prev_frame[:,:,::-1])\n",
    "    ax.set_title(\"Предыдущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax = fig.add_subplot(1, 2, 2)\n",
    "    ax.imshow(frame[:,:,::-1])\n",
    "    ax.set_title(\"Текущий кадр\", fontsize=18)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.subplots_adjust(top=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vis_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-02ef3799fc61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualize_metric_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_values_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene_changes_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# смена сцен\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vis_base' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vis_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e6d40a97ac53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualize_metric_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvis_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_values_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscene_changes_base\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# ошибается, это не смена сцен\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vis_base' is not defined"
     ]
    }
   ],
   "source": [
    "idx = 10\n",
    "visualize_metric_error(vis_base[idx][0], vis_base[idx][1], metric_values_base[scene_changes_base[idx]])\n",
    "# ошибается, это не смена сцен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def visualize_metric_values(metric_values, threshold, cuts = None):\n",
    "    sns.set()\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(metric_values, label='Значение метрики на кадрах')\n",
    "    plt.xlabel('Номер кадра')\n",
    "    plt.ylabel('Значение метрики')\n",
    "    plt.hlines(y=threshold, xmin=0, xmax=len(metric_values), linewidth=2, color='r', label='Пороговое значение')\n",
    "    \n",
    "    if cuts is not None:\n",
    "        for cut in cuts:\n",
    "            plt.axvline(x=cut, color='k', linestyle=':', linewidth=0.5, label='Смена сцены')\n",
    "\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metric_values_base' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3e4e8828529d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_metric_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_values_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuts_base\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metric_values_base' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_metric_values(metric_values_base, 2000, cuts_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как видим, очень плохо подобран порог, да и сам признак, похоже, сильно зашумлён. Попробуйте что-то своё!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ваше решение ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector(frames)`  \n",
    "* Строку (# GRADED FUNCTION: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: scene_change_detector\n",
    "\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "def scene_change_detector(frames, with_vis=False, cuts = None):\n",
    "    #print(threshold, Sobel_t, hist_threshold)\n",
    "    \n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    prev_frame = None\n",
    "    metric_values1 = []\n",
    "    model = joblib.load('model_new.pkl')\n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "    def brightness_metric(frame, prev_frame):\n",
    "        return np.abs(np.mean(frame) - np.mean(prev_frame))\n",
    "    def brightness_differense_metric(frame, prev_frame):\n",
    "        return np.abs(np.mean(frame - prev_frame))\n",
    "    def std_metric(frame, prev_frame):\n",
    "        return np.abs(np.std(frame) - np.std(prev_frame))\n",
    "    def std_diff_metric(frame, prev_frame):\n",
    "        return np.abs(np.std(frame - prev_frame))\n",
    "    def hist_metric(frame, prev_frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist1 = cv2.calcHist([frame], [0], None, [64], [1, 64])\n",
    "        hist2 = cv2.calcHist([prev_frame], [0], None, [64], [1, 64])\n",
    "        return np.abs((hist1 - hist2)).ravel()\n",
    "    def hist_corel_metric(frame, prev_frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist1 = cv2.calcHist([frame], [0], None, [64], [1, 64])\n",
    "        hist2 = cv2.calcHist([prev_frame], [0], None, [64], [1, 64])\n",
    "        return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    def hist_feature_metric(frame, prev_frame, gray=False, crop_x = 10, crop_y = 10):\n",
    "        height, width = 1, 1\n",
    "        if gray == False:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "            height, width = frame.shape\n",
    "        else:\n",
    "            height, width = frame.shape\n",
    "        cut = np.zeros((crop_x * crop_y, 4))\n",
    "        ind = 0\n",
    "        for ih in range(crop_y):\n",
    "            for iw in range(crop_x):\n",
    "                x = width//crop_x * iw \n",
    "                y = height//crop_y * ih\n",
    "                h = height // crop_y\n",
    "                w = width // crop_x\n",
    "                tmp_frame = frame[y:y+h, x:x+w]\n",
    "                tmp_prev_frame = prev_frame[y:y+h, x:x+w]\n",
    "                a = cv2.calcHist([tmp_frame], [0], None, [64], [1, 64])\n",
    "                b = cv2.calcHist([tmp_prev_frame], [0], None, [64], [1, 64])\n",
    "                cut[ind][0] = cv2.compareHist(a, b, cv2.HISTCMP_CORREL)\n",
    "                cut[ind][1] = cv2.compareHist(a, b, cv2.HISTCMP_INTERSECT)\n",
    "                cut[ind][2] = cv2.compareHist(a, b, cv2.HISTCMP_KL_DIV)\n",
    "                tmp_frame = tmp_frame / 255\n",
    "                tmp_prev_frame = tmp_prev_frame / 255\n",
    "                tmp = brightness_metric(tmp_frame, tmp_prev_frame) / 4\n",
    "                std1 = np.var(tmp_frame) / 2\n",
    "                std2 = np.var(tmp_prev_frame)\n",
    "                if std1 == 0 or std2 == 0:\n",
    "                    cut[ind][3] = (tmp + std1 * std2) ** 2 / 0.112\n",
    "                else:\n",
    "                    cut[ind][3] = (tmp + std1 * std2) ** 2 / (std1 * std2 * 2)\n",
    "                ind += 1\n",
    "        return list(np.mean(cut, axis = 0))\n",
    "    def cos_metric(frame, prev_frame):\n",
    "        tmp1 = np.sum(frame * prev_frame)\n",
    "        tmp = np.sqrt(np.sum(prev_frame**2))\n",
    "        tmp = np.sqrt(tmp * np.sum(frame**2))\n",
    "        if tmp == 0:\n",
    "            tmp = tmp1 / 0.0123\n",
    "        else:\n",
    "            tmp = tmp1 / tmp\n",
    "        return tmp\n",
    "    def hist_eq(frame):\n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(3,3))\n",
    "        cl = clahe.apply(l)\n",
    "        limg = cv2.merge((cl,a,b))\n",
    "        final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "        return final\n",
    "    def laplasian(frame):\n",
    "        frame1 = cv2.GaussianBlur(frame, (3, 3), 0)\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame1 = cv2.Laplacian(frame1, cv2.CV_16S, ksize=5)\n",
    "        abs_dst1 = cv2.convertScaleAbs(frame1)\n",
    "        return abs_dst1\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        # Основная часть вашего алгоритма\n",
    "        if prev_frame is not None:\n",
    "            fr = frame\n",
    "            fr_prev = prev_frame\n",
    "            metrics = []\n",
    "            #metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            #metrics.append(brightness_metric(fr, fr_prev))\n",
    "            #metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            metrics.append(std_metric(fr, fr_prev))\n",
    "            metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            tmp = hist_feature_metric(fr, fr_prev)\n",
    "            metrics.append(tmp[1])\n",
    "            metrics.append(tmp[3])\n",
    "            arr = hist_metric(fr, fr_prev)\n",
    "            metrics.append(np.mean(arr))\n",
    "            #metrics.append(np.std(arr))\n",
    "            metrics.append(cos_metric(fr, fr_prev))\n",
    "            \n",
    "            fr = laplasian(frame)\n",
    "            fr_prev = laplasian(prev_frame)\n",
    "            metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            ######metrics.append(brightness_metric(fr, fr_prev))\n",
    "            #metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            #metrics.append(std_metric(fr, fr_prev))\n",
    "            metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            #metrics.append(cos_metric(fr, fr_prev))\n",
    "            tmp = hist_feature_metric(fr, fr_prev, gray=True)\n",
    "            metrics.append(tmp[0])\n",
    "            metrics.append(tmp[2])\n",
    "            metrics.append(tmp[3])\n",
    "            #metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            #metrics += list(hist_metric(fr, fr_prev))\n",
    "            \n",
    "            fr = hist_eq(frame)\n",
    "            fr_prev = hist_eq(prev_frame)\n",
    "            metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            #metrics.append(brightness_metric(fr, fr_prev))\n",
    "            metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            metrics.append(std_metric(fr, fr_prev))\n",
    "            #metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            #metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            tmp = hist_feature_metric(fr, fr_prev)\n",
    "            metrics.append(tmp[1])\n",
    "            metrics.append(tmp[3])\n",
    "            arr = hist_metric(fr, fr_prev)\n",
    "            metrics.append(np.mean(arr))\n",
    "            #metrics.append(np.std(arr))\n",
    "            metrics.append(cos_metric(fr, fr_prev))\n",
    "\n",
    "            \n",
    "            fr = laplasian(fr)\n",
    "            fr_prev = laplasian(fr_prev)\n",
    "            metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            metrics.append(brightness_metric(fr, fr_prev))\n",
    "            #metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            #metrics.append(std_metric(fr, fr_prev))\n",
    "            metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            #metrics.append(cos_metric(fr, fr_prev))\n",
    "            #metrics += hist_feature_metric(fr, fr_prev, gray=True)\n",
    "            #metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            #metrics += list(hist_metric(fr, fr_prev))\n",
    "            \n",
    "            \n",
    "            #\n",
    "            metrics = np.array(metrics).reshape(1, -1)\n",
    "            lol = SimpleImputer(missing_values=np.inf, strategy='mean')\n",
    "            lol = lol.fit(metrics)\n",
    "            metrics = lol.transform(metrics)\n",
    "            lol = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "            lol = lol.fit(metrics)\n",
    "            metrics = lol.transform(metrics)\n",
    "            lol = SimpleImputer(missing_values=-np.inf, strategy='mean')\n",
    "            lol = lol.fit(metrics)\n",
    "            metrics = lol.transform(metrics)\n",
    "            metrics = np.array(metrics, dtype='float32')\n",
    "            #print(metrics)\n",
    "            \n",
    "            ans = model.predict(metrics)\n",
    "            '''if idx in cuts:\n",
    "                metrics.append(1)\n",
    "            else:\n",
    "                metrics.append(0)'''\n",
    "            #dataset.loc[idx] = metrics\n",
    "            if ans == 1:\n",
    "                scene_changes.append(idx)\n",
    "                if with_vis:\n",
    "                    # Кадры в памяти занимают много места, поэтому сохраним лишь первые 100 срабатываний\n",
    "                    if len(vis) < 100:\n",
    "                        vis.append([prev_frame, frame])\n",
    "        prev_frame = frame\n",
    "        ###  END CODE HERE  ###\n",
    "    return scene_changes, vis, metric_values#, metric_values1, metric_values2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n",
      "0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "for name in ['03', '04', '05', '07', '08', '10', '14', '17', '21', '22']:\n",
    "    fd = pd.read_csv(f'tmp_new/video_{name}_dataset.csv')\n",
    "    print(np.isinf(fd.values).mean(), np.isnan(fd.values).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = pd.read_csv('tmp_new/video_03_dataset.csv')\n",
    "np.isinf(fd.values).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frames = read_video(os.path.join('train_dataset', 'video', '03.mp4'))\n",
    "cuts = load_json_from_file(os.path.join('train_dataset', 'gt', '03.json'))['cut']\n",
    "scene_changes, vis, metric_values = scene_change_detector(frames, with_vis=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обратите внимание на скорость работы алгоритма! ####\n",
    "Если вычислять признаки без циклов по пикселям, а пользоваться методами из numpy, то скорость будет не медленнее 7-8 кадров в секунду.\n",
    "Например, вы можете использовать функцию `np.histogram` или `cv2.calcHist` для подсчёта гистограмм, а `cv2.Sobel` для применения оператора Собеля к кадру."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Посмотрим на найденные смены сцен\n",
    "idx = 1 \n",
    "visualize_metric_error(vis[idx][0], vis[idx][1], metric_values[scene_changes[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Посмотрим на значения метрики\n",
    "visualize_metric_values(metric_values, 2000, cuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подсчёт метрики F1-Score##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы оценивать алгоритм и научиться сравнивать несколько алгоритмов, нужна метрика качества. В данной задаче для оценки качества алгоритма используется F1-Score. Преимущества использования этой метрики к текущей постановке задачи смены сцен были рассказаны на лекции, напишем только формулы:\n",
    "$$precision = \\frac{tp}{tp+fp}$$\n",
    "$$recall = \\frac{tp}{tp+fn}$$\n",
    "$$F = 2 * \\frac{precision * recall}{precision+recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На всякий случай опишем как именно происходит подсчёт метрики для видео\n",
    "\n",
    "1) Сначала из выборки удаляются все кадры, которые по разметке либо являются сложными переходами между сценами, либо помечены как сложные для анализа и разметки (например, титры/обилие компьютерной графики и т.п)\n",
    "\n",
    "\n",
    "2) Затем для оставшихся кадров уже подсчитывается F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти пять клеток кода править не нужно\n",
    "def calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    for scd in predicted_scd:\n",
    "        if scd in true_scd:\n",
    "            tp += 1\n",
    "        elif scd not in not_to_use_frames:\n",
    "            fp += 1\n",
    "    for scd in true_scd:\n",
    "        if scd not in predicted_scd:\n",
    "            fn += 1\n",
    "    tn = scene_len - len(not_to_use_frames) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_precision(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_recall(tp, fp, tn, fn):\n",
    "    return tp / max(1, (tp + fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score(true_scd, predicted_scd, scene_len, not_to_use_frames=set()):\n",
    "    tp, fp, tn, fn = calculate_matrix(true_scd, predicted_scd, scene_len, not_to_use_frames)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_matrix(tp, fp, tn, fn):\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестируем разработанный метод сразу на нескольких видео ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, насколько хорошо работает разработанный метод. *Учтите, что итоговое тестирование будет производиться на аналогичном, но недоступном вам наборе видео, но все параметры алгоритмов должны быть указаны вами (иными словами - подобраны на тренировочном наборе).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        # Загружаем видео, его длину и смены сцен\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        # Составляем список сцен, которые не будут тестироваться\n",
    "        not_use_frames = set()\n",
    "        for type_scene_change in ['trash', 'fade', 'dissolve']:\n",
    "            for bad_scene_range in true_scene_changes.get(type_scene_change, []):\n",
    "                not_use_frames.update(list(range(bad_scene_range[0], bad_scene_range[1] + 1)))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        \n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix(\n",
    "            true_scene_changes['cut'],\n",
    "            predicted_scene_changes,\n",
    "            video_len,\n",
    "            not_use_frames\n",
    "        )\n",
    "        \n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn \n",
    "        print(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset = 'train_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная функция поможет вам посмотреть, на каких видео и на сколько ошибается ваш метод. Прогнать метод на отдельном видео и детально посмотреть кадры вы могли выше.\n",
    "\n",
    "Кроме того, с помощью этой функции вы можете подобрать оптимальные параметры для метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем базовый метод\n",
    "run_scene_change_detector_all_video(baseline_scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgenij/miniconda3/envs/evg/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e08884ebe248a48d8555872589730a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgenij/miniconda3/envs/evg/lib/python3.7/site-packages/ipykernel_launcher.py:99: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401c4e0f30d347aea0385c9a5712963f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-6e225f11fd15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Протестируем разработанный вами метод\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun_scene_change_detector_all_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscene_change_detector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-37495ca3273f>\u001b[0m in \u001b[0;36mrun_scene_change_detector_all_video\u001b[0;34m(scene_change_detector, dataset_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mnot_use_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_scene_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbad_scene_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredicted_scene_changes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscene_change_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         param_log['f1_score_{}'.format(video_info['source'])] = f1_score(\n",
      "\u001b[0;32m<ipython-input-27-ce7271a86ae4>\u001b[0m in \u001b[0;36mscene_change_detector\u001b[0;34m(frames, with_vis, cuts)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;31m#print(metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             '''if idx in cuts:\n\u001b[1;32m    182\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/evg/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/evg/lib/python3.7/site-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     82\u001b[0m                               \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                               \u001b[0mallow_nd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                               dtype=None)\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             ret = check_X_y(X, y,\n",
      "\u001b[0;32m~/miniconda3/envs/evg/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/evg/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video(scene_change_detector, video_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда вы смотрите на результат, обращайте внимание на **_mean_f1_score**  \n",
    "Именно по этой метрике будет производится финальное оценивание."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонусное задание: распознавание смен сцен типа \"наложения\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике кроме катов часто встречаются смены сцен, где происходит \"наложение\" одной сцены на другую:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dissolve.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ваше решение ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В качестве решения вы должны прикрепить функцию ниже. Все пороги должны быть указаны внутри функции.  \n",
    "Т.е. должен быть возможен вызов:  \n",
    "`scene_changes, vis, metric_values = scene_change_detector_dissolve(frames)`  \n",
    "* Строку (# GRADED FUNCTION: [function name]) менять **нельзя**. Она будет использоваться при проверке вашего решения.\n",
    "* Ячейка должна содержать только **одну** функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: scene_change_detector_dissolve\n",
    "\n",
    "import joblib\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "def scene_change_detector_dissolve(frames, with_vis=False, cuts = None):\n",
    "    #print(threshold, Sobel_t, hist_threshold)\n",
    "    \n",
    "    scene_changes = []\n",
    "    vis = []\n",
    "    metric_values = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Ваши внешние переменные\n",
    "    prev_frame = None\n",
    "    metric_values1 = []\n",
    "    model = joblib.load('model_new.pkl')\n",
    "    def pixel_metric(frame, prev_frame):\n",
    "        return np.mean((frame.astype(np.int32) - prev_frame) ** 2)\n",
    "    def brightness_metric(frame, prev_frame):\n",
    "        return np.abs(np.mean(frame) - np.mean(prev_frame))\n",
    "    def brightness_differense_metric(frame, prev_frame):\n",
    "        return np.abs(np.mean(frame - prev_frame))\n",
    "    def std_metric(frame, prev_frame):\n",
    "        return np.abs(np.std(frame) - np.std(prev_frame))\n",
    "    def std_diff_metric(frame, prev_frame):\n",
    "        return np.abs(np.std(frame - prev_frame))\n",
    "    def hist_metric(frame, prev_frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist1 = cv2.calcHist([frame], [0], None, [64], [1, 64])\n",
    "        hist2 = cv2.calcHist([prev_frame], [0], None, [64], [1, 64])\n",
    "        return np.abs((hist1 - hist2)).ravel()\n",
    "    def hist_corel_metric(frame, prev_frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "        hist1 = cv2.calcHist([frame], [0], None, [64], [1, 64])\n",
    "        hist2 = cv2.calcHist([prev_frame], [0], None, [64], [1, 64])\n",
    "        return cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)\n",
    "    def hist_feature_metric(frame, prev_frame, gray=False, crop_x = 10, crop_y = 10):\n",
    "        height, width = 1, 1\n",
    "        if gray == False:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "            height, width = frame.shape\n",
    "        else:\n",
    "            height, width = frame.shape\n",
    "        cut = np.zeros((crop_x * crop_y, 4))\n",
    "        ind = 0\n",
    "        for ih in range(crop_y):\n",
    "            for iw in range(crop_x):\n",
    "                x = width//crop_x * iw \n",
    "                y = height//crop_y * ih\n",
    "                h = height // crop_y\n",
    "                w = width // crop_x\n",
    "                tmp_frame = frame[y:y+h, x:x+w]\n",
    "                tmp_prev_frame = prev_frame[y:y+h, x:x+w]\n",
    "                a = cv2.calcHist([tmp_frame], [0], None, [64], [1, 64])\n",
    "                b = cv2.calcHist([tmp_prev_frame], [0], None, [64], [1, 64])\n",
    "                cut[ind][0] = cv2.compareHist(a, b, cv2.HISTCMP_CORREL)\n",
    "                cut[ind][1] = cv2.compareHist(a, b, cv2.HISTCMP_INTERSECT)\n",
    "                cut[ind][2] = cv2.compareHist(a, b, cv2.HISTCMP_KL_DIV)\n",
    "                tmp_frame = tmp_frame / 255\n",
    "                tmp_prev_frame = tmp_prev_frame / 255\n",
    "                tmp = brightness_metric(tmp_frame, tmp_prev_frame) / 4\n",
    "                std1 = np.var(tmp_frame) / 2\n",
    "                std2 = np.var(tmp_prev_frame)\n",
    "                if std1 == 0 or std2 == 0:\n",
    "                    cut[ind][3] = (tmp + std1 * std2) ** 2 / 0.112\n",
    "                else:\n",
    "                    cut[ind][3] = (tmp + std1 * std2) ** 2 / (std1 * std2 * 2)\n",
    "                ind += 1\n",
    "        return list(np.mean(cut, axis = 0))\n",
    "    def cos_metric(frame, prev_frame):\n",
    "        tmp1 = np.sum(frame * prev_frame)\n",
    "        tmp = np.sqrt(np.sum(prev_frame**2))\n",
    "        tmp = np.sqrt(tmp * np.sum(frame**2))\n",
    "        if tmp == 0:\n",
    "            tmp = tmp1 / 0.0123\n",
    "        else:\n",
    "            tmp = tmp1 / tmp\n",
    "        return tmp\n",
    "    def hist_eq(frame):\n",
    "        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(3,3))\n",
    "        cl = clahe.apply(l)\n",
    "        limg = cv2.merge((cl,a,b))\n",
    "        final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "        return final\n",
    "    def laplasian(frame):\n",
    "        frame1 = cv2.GaussianBlur(frame, (3, 3), 0)\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame1 = cv2.Laplacian(frame1, cv2.CV_16S, ksize=5)\n",
    "        abs_dst1 = cv2.convertScaleAbs(frame1)\n",
    "        return abs_dst1\n",
    "    ###  END CODE HERE  ###\n",
    "    \n",
    "    for idx, frame in tqdm(enumerate(frames), leave=False):\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        # Основная часть вашего алгоритма\n",
    "        if prev_frame is not None:\n",
    "            fr = frame\n",
    "            fr_prev = prev_frame\n",
    "            metrics = []\n",
    "            #metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            #metrics.append(brightness_metric(fr, fr_prev))\n",
    "            #metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            metrics.append(std_metric(fr, fr_prev))\n",
    "            metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            tmp = hist_feature_metric(fr, fr_prev)\n",
    "            metrics.append(tmp[1])\n",
    "            metrics.append(tmp[3])\n",
    "            arr = hist_metric(fr, fr_prev)\n",
    "            metrics.append(np.mean(arr))\n",
    "            #metrics.append(np.std(arr))\n",
    "            metrics.append(cos_metric(fr, fr_prev))\n",
    "            \n",
    "            fr = laplasian(frame)\n",
    "            fr_prev = laplasian(prev_frame)\n",
    "            metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            ######metrics.append(brightness_metric(fr, fr_prev))\n",
    "            #metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            #metrics.append(std_metric(fr, fr_prev))\n",
    "            metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            #metrics.append(cos_metric(fr, fr_prev))\n",
    "            tmp = hist_feature_metric(fr, fr_prev, gray=True)\n",
    "            metrics.append(tmp[0])\n",
    "            metrics.append(tmp[2])\n",
    "            metrics.append(tmp[3])\n",
    "            #metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            #metrics += list(hist_metric(fr, fr_prev))\n",
    "            \n",
    "            fr = hist_eq(frame)\n",
    "            fr_prev = hist_eq(prev_frame)\n",
    "            metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            #metrics.append(brightness_metric(fr, fr_prev))\n",
    "            metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            metrics.append(std_metric(fr, fr_prev))\n",
    "            #metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            #metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            tmp = hist_feature_metric(fr, fr_prev)\n",
    "            metrics.append(tmp[1])\n",
    "            metrics.append(tmp[3])\n",
    "            arr = hist_metric(fr, fr_prev)\n",
    "            metrics.append(np.mean(arr))\n",
    "            #metrics.append(np.std(arr))\n",
    "            metrics.append(cos_metric(fr, fr_prev))\n",
    "\n",
    "            \n",
    "            fr = laplasian(fr)\n",
    "            fr_prev = laplasian(fr_prev)\n",
    "            metrics.append(pixel_metric(fr, fr_prev)) \n",
    "            metrics.append(brightness_metric(fr, fr_prev))\n",
    "            #metrics.append(brightness_differense_metric(fr, fr_prev))\n",
    "            #metrics.append(std_metric(fr, fr_prev))\n",
    "            metrics.append(std_diff_metric(fr, fr_prev))\n",
    "            #metrics.append(cos_metric(fr, fr_prev))\n",
    "            #metrics += hist_feature_metric(fr, fr_prev, gray=True)\n",
    "            #metrics.append(hist_corel_metric(fr, fr_prev))\n",
    "            #metrics += list(hist_metric(fr, fr_prev))\n",
    "            \n",
    "            \n",
    "            #\n",
    "            metrics = np.array(metrics).reshape(1, -1)\n",
    "            lol = SimpleImputer(missing_values=np.inf, strategy='mean')\n",
    "            lol = lol.fit(metrics)\n",
    "            metrics = lol.transform(metrics)\n",
    "            lol = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "            lol = lol.fit(metrics)\n",
    "            metrics = lol.transform(metrics)\n",
    "            lol = SimpleImputer(missing_values=-np.inf, strategy='mean')\n",
    "            lol = lol.fit(metrics)\n",
    "            metrics = lol.transform(metrics)\n",
    "            #print(metrics)\n",
    "            \n",
    "            ans = model.predict(metrics)\n",
    "            '''if idx in cuts:\n",
    "                metrics.append(1)\n",
    "            else:\n",
    "                metrics.append(0)'''\n",
    "            #dataset.loc[idx] = metrics\n",
    "            if ans == 1:\n",
    "                scene_changes.append(idx)\n",
    "                if with_vis:\n",
    "                    # Кадры в памяти занимают много места, поэтому сохраним лишь первые 100 срабатываний\n",
    "                    if len(vis) < 100:\n",
    "                        vis.append([prev_frame, frame])\n",
    "        prev_frame = frame\n",
    "        ###  END CODE HERE  ###\n",
    "    return scene_changes, vis, metric_values#, metric_values1, metric_values2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества используется видоизменённый f1-score:\n",
    "\n",
    "Так как смена сцен не происходит за один кадр, попаданием считается попадание ответа смены сцен в отрезок, где происходит наложение.  \n",
    "**Обратите внимание**, что несколько раз указывать одну смену сцен не нужно.\n",
    "\n",
    "Попадание вне отрезков смен сцен путём наложения считается как false positive, не попадание в указанный отрезок - как false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Эти три клетки кода править не нужно\n",
    "def calculate_matrix_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    scene_len = scene_len\n",
    "    checked_dissolve_segments = set()\n",
    "    total_scene_dissolve_len = np.sum([dissolve_segment[1] - dissolve_segment[0] + 1 for dissolve_segment in true_scd])\n",
    "    for scd in predicted_scd:\n",
    "        for dissolve_segment in true_scd:\n",
    "            if scd in range(dissolve_segment[0], dissolve_segment[1] + 1):\n",
    "                tp += 1\n",
    "                checked_dissolve_segments.add(tuple(dissolve_segment))\n",
    "                break\n",
    "        else:\n",
    "            fp += 1\n",
    "    fn = len(true_scd) - len(checked_dissolve_segments)\n",
    "    tn = scene_len - total_scene_dissolve_len + len(true_scd) - tp - fp - fn\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def f1_score_dissolve(true_scd, predicted_scd, scene_len):\n",
    "    tp, fp, tn, fn = calculate_matrix_dissolve(true_scd, predicted_scd, scene_len)\n",
    "    precision_score = calculate_precision(tp, fp, tn, fn)\n",
    "    recall_score = calculate_recall(tp, fp, tn, fn)\n",
    "    if precision_score + recall_score == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * precision_score * recall_score / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_scene_change_detector_all_video_dissolve(scene_change_detector, dataset_path):\n",
    "    video_dataset = load_json_from_file(os.path.join(dataset_path, 'info.json'))\n",
    "    param_log = {\n",
    "        '_mean_f1_score': []\n",
    "    }\n",
    "    for video_info in tqdm(video_dataset, leave=False):\n",
    "        frames = read_video(os.path.join(dataset_path, video_info['source']))\n",
    "        video_len = video_info['len']\n",
    "        true_scene_changes = load_json_from_file(os.path.join(dataset_path, video_info['scene_change']))\n",
    "        \n",
    "        predicted_scene_changes, _, _ = scene_change_detector(frames)\n",
    "        param_log['f1_score_{}'.format(video_info['source'])] = f1_score_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        video_tp, video_fp, video_tn, video_fn = calculate_matrix_dissolve(\n",
    "            true_scene_changes.get('dissolve', []),\n",
    "            predicted_scene_changes,\n",
    "            video_len\n",
    "        )\n",
    "        param_log['tp_{}'.format(video_info['source'])] = video_tp\n",
    "        param_log['fp_{}'.format(video_info['source'])] = video_fp\n",
    "        param_log['tn_{}'.format(video_info['source'])] = video_tn\n",
    "        param_log['fn_{}'.format(video_info['source'])] = video_fn\n",
    "        param_log['_mean_f1_score'].append(param_log['f1_score_{}'.format(video_info['source'])])\n",
    "    param_log['_mean_f1_score'] = np.mean(param_log['_mean_f1_score'])\n",
    "    return param_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "video_dataset_path = 'train_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Протестируем разработанный вами метод\n",
    "run_scene_change_detector_all_video_dissolve(scene_change_detector_dissolve, video_dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немного об оценивании задания ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценивание задания будет производиться по следующей схеме:  \n",
    "\n",
    "Пусть на скрытой выборке по F-метрике вы получили X, лучшее решение получило Y.\n",
    "\n",
    "1. Базовая часть оценивется как $$20 * \\left(\\frac{\\max(0, X_{base} - 0.5)}{Y_{base} - 0.5}\\right)^2 + Bonus_{base}$$ Бонусные баллы $Bonus$ можно получить за оригинальные идеи в задаче или в её реализации\n",
    "2. Дополнительное задание оценивается как $$5 * \\frac{\\max(0, X_{add} - 0.1)}{Y_{add} - 0.1} + Bonus_{add}$$Процесс получения бонусных баллов аналогичен получению бонусных баллов в базовой части"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ваши ощущения ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*До дедлайна пару часов и вы никак не можете улучшить текущее решение? Или наоборот, вы всё сделали очень быстро? Опишите кратко ваши ощущения от задания - сколько времени вы потратили на задание, сколько вы потратили на изучение питона и установку необходимых библиотек, как быстро вы придумывали новые идеи и как они давали прирост по метрике и в целом насколько это задание вам понравилось и что хотели бы изменить/добавить.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
